{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ram(*i):\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(2, 3.4, 'abhishek')"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ram(2,3.4,\"abhishek\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpara/movie_triple_0.para\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/codecs.py:322\u001B[0m, in \u001B[0;36mBufferedIncrementalDecoder.decode\u001B[0;34m(self, input, final)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, final\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;66;03m# decode input (taking the buffer into account)\u001B[39;00m\n\u001B[1;32m    321\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer \u001B[38;5;241m+\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[0;32m--> 322\u001B[0m     (result, consumed) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;66;03m# keep undecoded input until the next call\u001B[39;00m\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer \u001B[38;5;241m=\u001B[39m data[consumed:]\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "pickle.load(open())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([552, 552, 552, ..., 610, 610, 610])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"para/movie_triple_2.para\")[\"train_i\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-11 20:03:01.885155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2022-11-11 20:03:02.009429: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n",
      "2022-11-11 20:03:02.013648: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n",
      "2022-11-11 20:03:02.013669: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n",
      "2022-11-11 20:03:02.035557: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2022-11-11 20:03:02.471055: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\r\n",
      "2022-11-11 20:03:02.471104: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\r\n",
      "2022-11-11 20:03:02.471110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n",
      "total number of users is  611\r\n",
      "total number of items is  9725\r\n",
      "Training : Epoch => 1:   2%|â–Ž                 | 73/3543 [00:08<07:19,  7.90it/s]^C\r\n",
      "  0%|                                                    | 0/15 [00:08<?, ?it/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/lord/PycharmProjects/HS-GCN/model_train.py\", line 115, in <module>\r\n",
      "    loss.backward()\r\n",
      "  File \"/home/lord/miniconda3/lib/python3.9/site-packages/torch/_tensor.py\", line 396, in backward\r\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\r\n",
      "  File \"/home/lord/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 173, in backward\r\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\r\n",
      "  File \"/home/lord/miniconda3/lib/python3.9/site-packages/torch/autograd/function.py\", line 243, in apply\r\n",
      "    def apply(self, *args):\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!python3 model_train.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
